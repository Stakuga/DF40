# Configuration for CLIP Detector with Grad-CAM support
# Based on the original clip detector configuration

# Model configuration
model_name: clip_gradcam  # Use the new detector with Grad-CAM support

# Loss function
loss_func: cross_entropy_loss

# Grad-CAM specific configuration
gradcam_enabled: true
gradcam_layers:
  - "encoder.layers.23"    # Last transformer layer  
  - "encoder.layers.20"    # Earlier layer for comparison
  - "encoder.layers.15"    # Even earlier layer
  - "encoder.layers.10"    # Mid-level features
gradcam_save_dir: "./gradcam_visualizations"

# Dataset configuration
dataset:
  train_dataset: "FaceForensics++"
  test_dataset: "FaceForensics++"
  compress: "c23"
  train_batchSize: 32
  test_batchSize: 32
  workers: 4
  frame_num:
    train: 8
    test: 8
  resolution: 224
  with_mask: false
  with_landmark: false

# Training configuration  
optimizer:
  type: Adam
  adam:
    lr: 0.0001
    beta1: 0.9
    beta2: 0.999
    eps: 0.00000001
    weight_decay: 0.0005
    amsgrad: false

# Learning rate scheduler
lr_scheduler:
  type: step
  step:
    step_size: 5
    gamma: 0.5

# Training parameters
epoches: 10
start_epoch: 0
save_interval: 1
save_ckpt: true

# Metrics
metric_scoring: auc

# Random seed
manualSeed: 10

# Logging
log_interval: 100
tensorboard_log: true

# Multi-GPU
ngpu: 1
